{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dev\n",
    "- 2020.12.06 DB -> Elasticsearch 자동화 코드"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "from kfp.components import func_to_container_op, InputPath, OutputPath\n",
    "from kfp import dsl\n",
    "import kfp\n",
    "import kfp.compiler as compiler\n",
    "import kfp.components as comp\n",
    "\n",
    "# Bike DB -> Component(Docker image)\n",
    "def get_data_op(file_path: OutputPath('json')) -> int:\n",
    "    \"\"\"Load data from database\"\"\"\n",
    "    import psycopg2\n",
    "    import pandas as pd\n",
    "    import datetime as dt\n",
    "    import json\n",
    "    import time\n",
    "    import requests # 미설치\n",
    "    from sqlalchemy import create_engine\n",
    "    from datetime import datetime\n",
    "    print('패키지 불러오기 성공 !')\n",
    "    \n",
    "    # [apiKey 출처 불분명]\n",
    "    def get_addr(X, Y):\n",
    "        apiKey='95B9D6ED-C2DB-3B0A-A43F-20FD442638CF'\n",
    "        r =requests.get(f'http://apis.vworld.kr/coord2jibun.do?x={X}&y={Y}\\\n",
    "        &apiKey={apiKey}&domain=http://map.vworld.kr/&output=json')\n",
    "        location = r.json()\n",
    "        try:\n",
    "            location = location['ADDR']\n",
    "        except:\n",
    "            location = ''\n",
    "        return location\n",
    "    \n",
    "    time.sleep(20)\n",
    "    NOW_DATE = datetime.now().date()\n",
    "    NOW_HOUR = datetime.now().hour\n",
    "    NOW_MINUTE = datetime.now().minute\n",
    "    \n",
    "    engine = create_engine(\"postgresql://postgres:6team123!@restored-aurora.cj92narf3bwn.ap-northeast-2.rds.amazonaws.com:5432/final_project\")\n",
    "    df = pd.read_sql(f\"\"\"\n",
    "    SELECT 대여소이름, 위도, 경도, 잔여대수, 거치율, 일시 \\\n",
    "    FROM bike \\\n",
    "    WHERE 일시>='{NOW_DATE} {NOW_HOUR}:{NOW_MINUTE}';\n",
    "    \"\"\",\n",
    "    con = engine,\n",
    "    parse_dates = ['created_at', 'updated_at'])\n",
    "    print('Postgres Engine 생성 완료 !')\n",
    "    \n",
    "    df['권역명'] = 0\n",
    "    df['권역명'] = df.apply(lambda x: get_addr(x['경도'], x['위도']), axis = 1)\n",
    "    df['권역명'] = df['권역명'].apply(lambda x: x.split(' ')[1] if len(x) > 1 else x)\n",
    "    \n",
    "    \n",
    "    target = []\n",
    "    gu = ['은평구', '은평구', '성북구', '강남구']\n",
    "    \n",
    "    \n",
    "    for row, g in zip(df[df['권역명'] == ''].iterrows(), gu):\n",
    "        target.append((row[1]['위도'], row[1]['경도'], g))\n",
    "    try:    \n",
    "        for x in df[df['권역명'] == ''].iterrows():\n",
    "            for t in target:\n",
    "                if (x[1]['위도'] == t[0]) & (x[1]['경도'] == t[1]):\n",
    "                    df.at[x[0], '권역명'] = t[2]\n",
    "        print('권역명 Null값 보정 성공 !')\n",
    "    except:\n",
    "        print('[Error]권역명 Null값 보정 실패 !')\n",
    "    \n",
    "    \n",
    "    df['location'] = df['위도'].astype('str') + ',' + df['경도'].astype('str')\n",
    "    df = df[['대여소이름', '거치율', '잔여대수', '일시', 'location', '권역명']]\n",
    "    df['일시'] = df['일시'].apply(lambda x: x.isoformat())\n",
    "    print('데이터 전처리 완료 !')\n",
    "    \n",
    "    documents = df.to_dict(orient='records')\n",
    "    print('Dataframe 데이터 json 변환 완료 ')\n",
    "    \n",
    "    with open(file_path, 'w') as writer:\n",
    "        json.dump(documents,writer)\n",
    "        \n",
    "    NOW = datetime.now()\n",
    "    length = len(documents)\n",
    "    print(f'[{NOW}]DB로부터 {length}개의 document 생성 완료!')\n",
    "    \n",
    "    if (NOW_HOUR == 0) & (NOW_MINUTE == 0):\n",
    "        return 0\n",
    "    return 1\n",
    "    \n",
    "    \n",
    "def elasticsearch_create_index_op():\n",
    "    \"\"\"Create Elasticsearch Index everyday\"\"\"\n",
    "    import elasticsearch\n",
    "    import datetime as dt\n",
    "    from elasticsearch import Elasticsearch \n",
    "    from elasticsearch.helpers import bulk\n",
    "    from datetime import datetime\n",
    "    \n",
    "    def connect_elasticsearch():\n",
    "        es = None\n",
    "        es = Elasticsearch(hosts=\"https://elastic:brYj4OIjnlBAdj0uZ4TFWhF0@90f0365b5bfa4dbf9aa9b43b4af8e16b.ap-northeast-2.aws.elastic-cloud.com:9243\")\n",
    "\n",
    "        if es.ping():\n",
    "            print('Elasticsearch 연결 성공!')\n",
    "        else:\n",
    "            print('Elasticsearch 연결 실패!')\n",
    "        return es\n",
    "    es = connect_elasticsearch()\n",
    "    mappings = {\n",
    "       \"mappings\": {\n",
    "           \"properties\" : {\n",
    "             \"대여소이름\" : {\"type\" : \"keyword\"},\n",
    "             \"거치율\" : {\"type\" : \"integer\"},\n",
    "             \"잔여대수\" : {\"type\" : \"integer\"},\n",
    "             \"일시\" : {\"type\" : \"date\"},\n",
    "             \"location\": {\"type\": \"geo_point\"},\n",
    "             \"권역명\" : {\"type\" : \"keyword\"}\n",
    "             }\n",
    "          }\n",
    "       }\n",
    "    \n",
    "    DATE = datetime.today().date()\n",
    "    NOW = datetime.now()\n",
    "    res =  es.indices.get_alias(\"*\")\n",
    "    if f'ddareungi-{DATE}' not in res:\n",
    "        es.indices.create(index=f'ddareungi-{DATE}',body=mappings)\n",
    "        print(f'[{NOW}]ddareungi-{DATE} 인덱스 생성 완료!')\n",
    "    else:\n",
    "        print(f'[{NOW}]ddareungi-{DATE} 인덱스가 이미 존재합니다!')\n",
    "\n",
    "    \n",
    "# Component(Docker image) -> Elasticsearch\n",
    "def elasticsearch_insert_doc_op(file_path: InputPath('json')):\n",
    "    \"\"\"Insert document to Elasticsearch every 5 minunte\"\"\"\n",
    "    import elasticsearch\n",
    "    import pandas as pd\n",
    "    import datetime as dt\n",
    "    import json\n",
    "    from elasticsearch import Elasticsearch \n",
    "    from elasticsearch.helpers import bulk\n",
    "    from datetime import datetime\n",
    "    \n",
    "    with open(file_path, 'r') as doc:\n",
    "        documents = json.load(doc)\n",
    "        \n",
    "    def connect_elasticsearch():\n",
    "        es = None\n",
    "        es = Elasticsearch(hosts=\"https://elastic:brYj4OIjnlBAdj0uZ4TFWhF0@90f0365b5bfa4dbf9aa9b43b4af8e16b.ap-northeast-2.aws.elastic-cloud.com:9243\")\n",
    "\n",
    "        if es.ping():\n",
    "            print('Elasticsearch 연결 성공!')\n",
    "        else:\n",
    "            print('Elasticsearch 연결 실패!')\n",
    "        return es\n",
    "    es = connect_elasticsearch()\n",
    "    DATE = datetime.today().date()\n",
    "    bulk(es, documents, stats_only = True, index=f'ddareungi-{DATE}')\n",
    "    \n",
    "    NOW = datetime.now()\n",
    "    length = len(documents)\n",
    "    print(f'[{NOW}]Elasticsearch로 {length}개의 document 삽입 완료!')\n",
    "\n",
    "# Create Operator\n",
    "base_image='941102633028.dkr.ecr.ap-northeast-2.amazonaws.com/6team:es_ko_KST'\n",
    "get_data_op_ = func_to_container_op(\n",
    "                func = get_data_op, \n",
    "                base_image = base_image, \n",
    "                packages_to_install = ['requests==2.22.0']\n",
    "                )\n",
    "elasticsearch_create_index_op_ = func_to_container_op(\n",
    "                                func = elasticsearch_create_index_op, \n",
    "                                base_image = base_image) \n",
    "elasticsearch_insert_doc_op_  = func_to_container_op(\n",
    "                                func = elasticsearch_insert_doc_op, \n",
    "                                base_image = base_image)\n",
    "\n",
    "@dsl.pipeline(\n",
    "    name='data-to-elasticsearch',\n",
    "    description='to insert data to elasticsearch'\n",
    ")\n",
    "def elasticsearch_pipeline():\n",
    "    data_op_ = get_data_op_()\n",
    "    with dsl.Condition(data_op_.outputs['output'] == 0):\n",
    "        create_index_op_ = elasticsearch_create_index_op_()\n",
    "        insert_doc_op_= elasticsearch_insert_doc_op_(data_op_.outputs['file'])\n",
    "        insert_doc_op_.after(create_index_op_)\n",
    "    with dsl.Condition(data_op_.outputs['output'] == 1):\n",
    "        insert_doc_op_= elasticsearch_insert_doc_op_(data_op_.outputs['file'])\n",
    "        \n",
    "\n",
    "\n",
    "compiler.Compiler().compile(elasticsearch_pipeline, elasticsearch_pipeline.__name__ + '.pipeline.zip')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
